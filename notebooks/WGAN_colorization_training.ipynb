{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook has been used for WGAN training**\n",
        "\n"
      ],
      "metadata": {
        "id": "3Z5saPJZiV6S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e54QtGM-4FGH"
      },
      "source": [
        "# 1 Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk3EcePY4PV1"
      },
      "source": [
        "Two datasets are used: a small version of COCO dataset with 21,837 images and one with 17,178 images of animals (12 categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B0UnTf94ndc"
      },
      "source": [
        "##1.1 Animals dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbIXQR5B5Qty"
      },
      "source": [
        "We download this dataset from kaggle (1.4 GB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LyAJsIy4H9R"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW1I4x0j5dLh"
      },
      "source": [
        "You have to upload a file called kaggle.json. To obtain it you need to follow the first 2 steps described in https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcwM9NAY5cJQ"
      },
      "outputs": [],
      "source": [
        "files.upload();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgTBTr6f5yv8"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X-z45AP54t6"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d piyushkumar18/animal-image-classification-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7psYmO6Dmv"
      },
      "source": [
        "The data have been downloaded. To unzip them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldwePf3c59cJ"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/animal_data\n",
        "!unzip -qq /content/animal-image-classification-dataset.zip -d /content/animal_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sILCvtJ8rbC"
      },
      "source": [
        "## 1.2 COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grBxE-GZ8v1g"
      },
      "source": [
        "To download it we use fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of1FTMIW8VXG"
      },
      "outputs": [],
      "source": [
        "!pip install fastai==2.4;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGmlvToL83YY"
      },
      "outputs": [],
      "source": [
        "from fastai.data.external import untar_data, URLs\n",
        "import os\n",
        "import glob\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oQGGmVW83uq"
      },
      "outputs": [],
      "source": [
        "coco_path = untar_data(URLs.COCO_SAMPLE)\n",
        "coco_path = str(coco_path) + \"/train_sample\"\n",
        "\n",
        "paths = glob.glob(coco_path+\"/*.jpg\")\n",
        "paths =np.array(paths)\n",
        "num_images_coco = len(paths)\n",
        "print(f\"# coco images: {num_images_coco}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDax1udw8PRC"
      },
      "source": [
        "Uplaod either data_small_training.txt or data_big_training.txt (we have used only the small dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhULxpYT8Sla"
      },
      "outputs": [],
      "source": [
        "files.upload();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D-j-Gmw8jpP"
      },
      "outputs": [],
      "source": [
        "filename = \"data_small_training.txt\"\n",
        "\n",
        "def read_lines(path):\n",
        "\n",
        "  lines = None\n",
        "\n",
        "  with open(path) as file:\n",
        "    lines = [line.rstrip() for line in file]\n",
        "\n",
        "  return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kkkSVU8sUl",
        "outputId": "ded1054d-6db1-467c-8f8e-bb5d09a0743e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9600 images for training\n"
          ]
        }
      ],
      "source": [
        "training_paths = read_lines(filename)\n",
        "print(f\"{len(training_paths)} images for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LOVOSm0b9QU"
      },
      "source": [
        "# 2 Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w-5Nc7mgY38"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya73EyyAkVV3"
      },
      "source": [
        "## 2.1 Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyNuqjo6peDz"
      },
      "outputs": [],
      "source": [
        "SIZE = 256\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtCJVViBrLMK"
      },
      "outputs": [],
      "source": [
        "class GrayToColorDataset(Dataset):\n",
        "\n",
        "  def __init__(self, paths, transform = None):\n",
        "    \n",
        "    self.paths = paths\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    img_rgb = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "    img_rgb = self.transform(img_rgb)\n",
        "    img_rgb = np.array(img_rgb)\n",
        "\n",
        "    #RGB -> Lab\n",
        "    img_lab = rgb2lab(img_rgb).astype(\"float32\")\n",
        "    img_lab = transforms.ToTensor()(img_lab)\n",
        "\n",
        "    #to have values in range [-1,1]\n",
        "    L = img_lab[[0],:]/50. - 1.\n",
        "    ab = img_lab[[1,2],:] / 110.\n",
        "\n",
        "    return (L,ab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwCDspxZrYlp"
      },
      "outputs": [],
      "source": [
        "train_dataset = GrayToColorDataset(training_paths, train_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "222dWNwbrpeJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "PIN_MEMORY = True\n",
        "N_WORKERS = 2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS,\n",
        "                            pin_memory=PIN_MEMORY, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNsZnfNfsiBg"
      },
      "source": [
        "# 3 cGAN models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkM2-UhsvBp"
      },
      "source": [
        "## 3.1 Generator: U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Vnxybgnsr2Y"
      },
      "outputs": [],
      "source": [
        "class UNetDown(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size = 4, normalization_type = None, dropout = 0.0, activation = None):\n",
        "\n",
        "    super(UNetDown, self).__init__()\n",
        "\n",
        "    #if batchnorm/instancenorm used, bias not used\n",
        "\n",
        "    use_bias = normalization_type == None\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size, 2, 1, bias = use_bias)]\n",
        "\n",
        "    if not use_bias:\n",
        "      if normalization_type == \"instance\":\n",
        "\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "      else:\n",
        "\n",
        "        layers.append( nn.BatchNorm2d(out_channels))\n",
        "        \n",
        "    if activation == None:\n",
        "      layers.append(nn.LeakyReLU(negative_slope = 0.2))\n",
        "\n",
        "    if activation == \"ReLU\":\n",
        "\n",
        "      layers.append(nn.ReLU())\n",
        "\n",
        "    if dropout:\n",
        "\n",
        "      layers.append(nn.Dropout(p = dropout))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqTa1lzVtnwT"
      },
      "outputs": [],
      "source": [
        "class UNetUp(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size = 4,  normalization_type = None, dropout = 0.0):\n",
        "\n",
        "    super(UNetUp, self).__init__()\n",
        "\n",
        "    use_bias = normalization_type == None\n",
        "\n",
        "    layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, 2, 1, bias = use_bias)]\n",
        "\n",
        "    if not use_bias:\n",
        "      if normalization_type == \"instance\":\n",
        "\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "      else:\n",
        "\n",
        "        layers.append( nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    layers.append(nn.ReLU())\n",
        "\n",
        "    if dropout:\n",
        "\n",
        "      layers.append(nn.Dropout(p = dropout))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, x, skip = None):\n",
        "      x = self.model(x)\n",
        "      if skip is not None:\n",
        "\n",
        "        x = torch.cat((skip, x), 1)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UQKVsqrtqtM"
      },
      "outputs": [],
      "source": [
        "class GeneratorUNet(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels = 1, out_channels = 2, num_down = 8, ngf = 64, normalization_type = None):\n",
        "\n",
        "    super(GeneratorUNet, self).__init__()\n",
        "\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.ups = nn.ModuleList()\n",
        "    \n",
        "\n",
        "    features =[ngf]\n",
        "\n",
        "    for i in range(3):\n",
        "\n",
        "      features.append(features[i]*2)\n",
        "\n",
        "    features.append(features[-1])\n",
        "    #64, 128, 256, 512, 512\n",
        "\n",
        "    if num_down > 5:\n",
        "\n",
        "      features += [ngf * 8 for i in range(num_down - 5)]\n",
        "    #for num_down = 8: 64, 128, 256, 512, 512, 512, 512, 512 (->1x1 for input size 256x256)\n",
        "\n",
        "\n",
        "    #ENCODER (CONTRACTING PATH)\n",
        "\n",
        "    #outermost down block: no normalization and no dropout, only downconv\n",
        "    self.downs.append(UNetDown(in_channels, ngf, 4))\n",
        "\n",
        "    in_channels = ngf #new in_channels for the next down-block\n",
        "    \n",
        "    for i,n_features in enumerate(features[1:len(features)-1]):\n",
        "      #no dropout\n",
        "      self.downs.append(UNetDown(in_channels, n_features, 4, normalization_type, 0.0))\n",
        "      in_channels = n_features\n",
        "\n",
        "    \n",
        "    #innermost down block: no normalization and no dropout, only downconv\n",
        "    self.downs.append(UNetDown(in_channels, features[-1], 4, activation = \"ReLU\"))\n",
        "    \n",
        "\n",
        "    #DECODER (EXPANSIVE PATH)\n",
        "    i_channels = in_channels\n",
        "    for i, n_features in enumerate((features[-2::-1])):\n",
        "      \n",
        "      \n",
        "      #if i == 0, innermost(bottleneck), namely a block such that after down we go up. no dropout\n",
        "      i_channels = in_channels if i == 0  else i_channels * 2\n",
        "\n",
        "      #no dropout for the first up and the last 4 ups \n",
        "      dropout = 0.0 if (i == 0 or i  > 3) else 0.5\n",
        "\n",
        "      self.ups.append(UNetUp(i_channels, n_features, 4, normalization_type, dropout))\n",
        "      i_channels = n_features\n",
        "    \n",
        "    \n",
        "    self.final = nn.Sequential(\n",
        "        nn.ConvTranspose2d(ngf*2,out_channels, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    skip_connections = list()\n",
        "\n",
        "    #encoder\n",
        "    for down in self.downs:\n",
        "\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "\n",
        "    #decoder with skip connections\n",
        "    for i, up in enumerate(self.ups):\n",
        "      \n",
        "      x = up(x, skip_connections[-i-2])\n",
        "\n",
        "    return self.final(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EakwAjpstItC"
      },
      "source": [
        "## 3.2 Discrimintor: PatchGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfSxSbH5-fle"
      },
      "source": [
        "The descriminator is a PatchGAN for $N \\times N$ patches where $N=70$: given an input $256 \\times 256$ the output is $30 \\times 30$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIK5GgDytMoi"
      },
      "outputs": [],
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels = 3, ndf = 64, n_down = 5, normalization_type = \"batchnorm\"):\n",
        "\n",
        "    super(PatchDiscriminator, self).__init__()\n",
        "\n",
        "    features = [ndf * 2**i for i in range(n_down-1)]\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(len(features)):\n",
        "      use_bias = True if i < 1  else False\n",
        "      stride = 2 if i < (len(features)-1) else 1\n",
        "      layers.append(nn.Conv2d(in_channels, features[i], 4, stride, 1, bias = use_bias))\n",
        "\n",
        "      if not use_bias:\n",
        "        if normalization_type == \"batchnorm\":\n",
        "          layers.append(nn.BatchNorm2d(features[i]))\n",
        "          \n",
        "        if normalization_type == \"instance\":\n",
        "          layers.append(nn.InstanceNorm2d(features[i]))\n",
        "\n",
        "\n",
        "      layers.append(nn.LeakyReLU(0.2))\n",
        "\n",
        "      in_channels = features[i]\n",
        "    \n",
        "    layers.append(nn.Conv2d(in_channels, 1, 4, 1, 1))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Vf25pPUZJR"
      },
      "source": [
        "# 4 Models initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vdfiGrcUl-p"
      },
      "source": [
        "Initialization generator and critic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joKhtB9AUpdr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "C = PatchDiscriminator(normalization_type = \"instance\").to(device)\n",
        "\n",
        "def weights_init(m):\n",
        "\n",
        "    classname = m.__class__.__name__\n",
        "\n",
        "    if classname.find('Conv') != -1:\n",
        "        #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "        if hasattr(m, 'bias') and m.bias is not None:\n",
        "          nn.init.constant_(m.bias.data, 0.0)\n",
        "    \n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "G.apply(weights_init);\n",
        "C.apply(weights_init);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G64C5Nv9NSmx"
      },
      "source": [
        "# 5 Training setup\n",
        "\n",
        "Here we define the L1 loss, the optimizers, the number of epochs and the hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1fteHZMOkD8"
      },
      "source": [
        "## 5.1 Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLQtSVlwPNnf"
      },
      "outputs": [],
      "source": [
        "#GAN_loss = GANLoss(device) \n",
        "L1_loss = nn.L1Loss()\n",
        "\n",
        "#L1 hyperparam\n",
        "\n",
        "lamb = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5qyRPWGPpPD"
      },
      "source": [
        "## 5.2 Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC4Vqh1jNxIB"
      },
      "outputs": [],
      "source": [
        "#params for Adam\n",
        "lr_G = 2e-4 \n",
        "lr_C = 2e-4\n",
        "\n",
        "betas_G = (0.5, 0.999)\n",
        "betas_C = (0.0, 0.9)\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)\n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptf8P0-HQR0f"
      },
      "source": [
        "# 6 Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV9IHLHdQU0N"
      },
      "outputs": [],
      "source": [
        "def convert_lab_to_rgb(L, ab):\n",
        "\n",
        "  \"\"\"\n",
        "  Provided a Lab image or a batch of Lab images, it returns it/them in RGB format \n",
        "  input:\n",
        "    - L: torch.tensor\n",
        "    - ab: torch.tensor\n",
        "  \n",
        "  output:\n",
        "    - img: numpy.ndarray (the rgb images)\n",
        "  \"\"\"\n",
        "\n",
        "  #check shape (one image or a batch)\n",
        "\n",
        "  is_batch = len(ab.shape) > 3\n",
        "  \n",
        "  L = (L+1.)*50.\n",
        "  ab = ab*110.\n",
        "\n",
        "  if is_batch:\n",
        "    # input tensors: N x 1 x 256 x 256, N x 2 x 256 x 256\n",
        "    Lab_images = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "  else:\n",
        "    # input tensors: 1 x 256 x 256, 2 x 256 x 256\n",
        "    Lab_image = torch.cat([L, ab], dim=0).permute(1, 2, 0).cpu().detach().numpy()\n",
        "    return lab2rgb(Lab_image)\n",
        "\n",
        "  rgb_images = list()\n",
        "\n",
        "  for image in Lab_images:\n",
        "\n",
        "    img_rgb = lab2rgb(image)\n",
        "    rgb_images.append(img_rgb)\n",
        "\n",
        "  return np.stack(rgb_images, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBi11kGaWoiR"
      },
      "outputs": [],
      "source": [
        "def show_results(Ls, real_abs, fake_abs):\n",
        "\n",
        "  \"\"\"\n",
        "  provided a batch of real and fake images, visualize them (+ the gray images)\n",
        "  input:\n",
        "    - Ls: batch with L for each image, N x 1 x 256 x 256 tensor\n",
        "    - real_abs: batch with ab for each real image, N x 2 x 256 x 256 tensor\n",
        "    - fake_abs: batch with ab for each fake image, N x 2 x 256 x 256 tensor\n",
        "  \"\"\"\n",
        "\n",
        "  n_cols = Ls.shape[0]\n",
        "\n",
        "  real_images = convert_lab_to_rgb(Ls, real_abs)\n",
        "  fake_images = convert_lab_to_rgb(Ls, fake_abs)\n",
        "\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "  for i in range(n_cols):\n",
        "\n",
        "    ax = plt.subplot(3, n_cols, i+1)\n",
        "    ax.imshow(Ls[i][0].cpu(), cmap='gray')\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    ax = plt.subplot(3, n_cols, i+1+n_cols)\n",
        "    ax.imshow(real_images[i])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    ax = plt.subplot(3, n_cols, i+1+2*n_cols)\n",
        "    ax.imshow(fake_images[i])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc5APyfh3_hM"
      },
      "source": [
        "The following class allows to track the losses over an epoch: it accumilates the losses over the dataset for each loss (WGAN_loss for the generator, for the discriminator, etc.). Then allows to compute the mean of each losses. In this way we can compute the mean loss at each epoch and also for intermediate steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WlY0NU2v6Yo"
      },
      "outputs": [],
      "source": [
        "class WLossTracker :\n",
        "  def __init__(self) :\n",
        "\n",
        "    self.G_count = 0 #n of images seen up to now\n",
        "    self.D_count = 0 #n of images seen up to now\n",
        "    \n",
        "    self.avg = {} #dict with avg of losses\n",
        "\n",
        "    self.G_dict_losses = {\n",
        "        \"G_loss\" : 0,\n",
        "        \"G_WGAN_loss\" : 0,\n",
        "        \"G_L1_loss\" : 0,\n",
        "\n",
        "    }\n",
        "\n",
        "    self.D_dict_losses = {\n",
        "        \"D_loss\" : 0,\n",
        "        \"D_loss_real\" : 0,\n",
        "        \"D_loss_fake\" : 0,\n",
        "        \"GP\" : 0\n",
        "    }\n",
        "\n",
        "  def set_to_zero(self) :\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    for key in self.G_dict_losses :\n",
        "      self.G_dict_losses[key] = 0\n",
        "\n",
        "    for key in self.D_dict_losses :\n",
        "      self.D_dict_losses[key] = 0\n",
        "\n",
        "    self.G_count = 0  \n",
        "    self.D_count = 0 \n",
        "\n",
        "\n",
        "  def update_G_losses(self, losses, batch_size) :\n",
        "    \"\"\"\n",
        "    It updates the cumulative sum for the losses\n",
        "\n",
        "    - losses: dict, the losses obtained in a single batch of dimension batch_size\n",
        "    - batch_size: int\n",
        "    \"\"\"\n",
        "    for key in losses :\n",
        "      self.G_dict_losses[key] += losses[key] * batch_size\n",
        "\n",
        "    self.G_count += batch_size\n",
        "\n",
        "  def update_D_losses(self, losses, batch_size) :\n",
        "    \"\"\"\n",
        "    It updates the cumulative sum for the losses\n",
        "\n",
        "    - losses: dict, the losses obtained in a single batch of dimension batch_size\n",
        "    - batch_size: int\n",
        "    \"\"\"\n",
        "    for key in losses :\n",
        "      self.D_dict_losses[key] += losses[key] * batch_size\n",
        "\n",
        "    self.D_count += batch_size\n",
        "\n",
        "\n",
        "\n",
        "  def avg_losses(self) : \n",
        "\n",
        "    \"\"\"\n",
        "     for each loss metric compute the mean w.r.t. the \n",
        "     losses accumulate up to now\n",
        "    \"\"\"\n",
        "\n",
        "    for key in self.G_dict_losses :\n",
        "      self.avg[key] = self.G_dict_losses[key] / self.G_count \n",
        "\n",
        "    for key in self.D_dict_losses :\n",
        "      self.avg[key] = self.D_dict_losses[key] / self.D_count \n",
        "\n",
        "    return self.avg\n",
        "\n",
        "\n",
        "  def print_losses(self) :\n",
        "\n",
        "    \"\"\"\n",
        "    print of the mean loss for each loss metric\n",
        "    \"\"\"\n",
        "\n",
        "    for key in self.avg :\n",
        "      temp = self.avg[key]\n",
        "      print(f\"{key} : {temp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4m5mkrdM3u"
      },
      "source": [
        "The following functions are used to save and load checkpoints during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUXrAtbcavh4"
      },
      "outputs": [],
      "source": [
        "def wsave_checkpoint(epoch, model_G, model_D, opt_G, opt_D, dict_losses):\n",
        "  \"\"\"\n",
        "  Provided the current epoch, G, D, optG, optD, and the losses, this function saves a checkpoint\n",
        "  \"\"\"\n",
        "\n",
        "  dict_save = {\n",
        "                'epoch': epoch,\n",
        "                'G_state_dict': model_G.state_dict(),\n",
        "                'G_opt_state_dict': opt_G.state_dict(),\n",
        "                'D_state_dict' : model_D.state_dict(),\n",
        "                'D_opt_state_dict' : opt_D.state_dict(),\n",
        "                'G_WGAN_loss' : dict_losses['G_WGAN_loss'],\n",
        "                'D_loss' : dict_losses['D_loss'],\n",
        "                'G_loss' : dict_losses['G_loss']\n",
        "              }\n",
        "\n",
        "  #dict_save.update(dict_losses)\n",
        "  #print(dict_save)\n",
        "\n",
        "  torch.save(dict_save, \"WGAN_training.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgmbZ03LdkPw"
      },
      "outputs": [],
      "source": [
        "def wload_checkpoint(G, D, opt_G, opt_D, path = \"/content/WGAN_training.pt\"):\n",
        "\n",
        "  \"\"\"\n",
        "  - G: Generator model, GeneratorUNet\n",
        "  - D: critic model, PatchDiscriminator \n",
        "  - opt_G: optimizer for G\n",
        "  - opt_D: optimizer for D\n",
        "  \n",
        "  - path: path to the file from which load the checkpoint\n",
        "  \"\"\"\n",
        "\n",
        "  checkpoint = torch.load(path)\n",
        "  epoch = checkpoint['epoch']\n",
        "  G.load_state_dict(checkpoint['G_state_dict'])\n",
        "  D.load_state_dict(checkpoint['D_state_dict'])\n",
        "\n",
        "  opt_D.load_state_dict(checkpoint['D_opt_state_dict'])\n",
        " \n",
        "  opt_G.load_state_dict(checkpoint['G_opt_state_dict'])\n",
        "\n",
        "\n",
        "  print(f\"Checkpoint at epoch {epoch} loaded\")\n",
        "\n",
        "  return epoch, {'G_WGAN_loss' : checkpoint['G_WGAN_loss'], 'D_loss' : checkpoint['D_loss'], 'G_loss' : checkpoint['G_loss']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMKteS3jVO7"
      },
      "source": [
        "Functions to save and load only the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGQ3wlPsjZb4"
      },
      "outputs": [],
      "source": [
        "def save_generator(G, path = \"/content/WGAN-gen.pt\"):\n",
        "\n",
        "  torch.save(G.state_dict(), path)\n",
        "\n",
        "def load_generator(G, path = \"/content/WGAN-gen.pt\"):\n",
        "\n",
        "  G.load_state_dict(torch.load(path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nL-1fBSogYu"
      },
      "source": [
        "Create and update a .csv file with all the losses during the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAUDlSSTohCO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from csv import writer\n",
        "\n",
        "wloss_names = ['G_loss', 'G_WGAN_loss', 'G_L1_loss', 'D_loss_real', 'D_loss_fake', 'D_loss', 'GP']\n",
        "\n",
        "def create_csv(columns = wloss_names, path = \"/content/wlosses.csv\"):\n",
        "\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "  df.to_csv(path)\n",
        "\n",
        "def update_csv(epoch, losses, columns = wloss_names, path = \"/content/wlosses.csv\"):\n",
        "\n",
        "  row_1 = [epoch]\n",
        "  row_2 = [losses[column] for column in columns]\n",
        "\n",
        "  row_to_add = row_1 + row_2\n",
        "\n",
        "  with open(path, 'a') as f_object:\n",
        "\n",
        "    writer_object = writer(f_object)\n",
        " \n",
        "    writer_object.writerow(row_to_add)\n",
        "\n",
        "    f_object.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kQG-T2DQVEJ"
      },
      "source": [
        "# 7 Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm_1wEoRm6sp"
      },
      "source": [
        "## 7.1 Functions for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KeLTt_UyKoL"
      },
      "source": [
        "Function that computes the GP term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roNg19LtyJ1d"
      },
      "outputs": [],
      "source": [
        "def GP_penalty_term(critic, real_imgs, fake_imgs, device) :\n",
        "\n",
        "  alpha = torch.rand((real_imgs.shape[0], 1, 1, 1), device = device)\n",
        "  \n",
        "  interpolates = (alpha * real_imgs + ((1 - alpha) * fake_imgs)).requires_grad_(True)\n",
        "  out_interpolates = critic(interpolates)\n",
        "\n",
        "  grad_outputs = torch.ones(out_interpolates.size(), device = device, requires_grad = False)\n",
        "\n",
        "  gradients = torch.autograd.grad(\n",
        "      outputs = out_interpolates,\n",
        "      inputs = interpolates,\n",
        "      grad_outputs = grad_outputs,\n",
        "      create_graph = True,\n",
        "      retain_graph = True,\n",
        "      only_inputs = True,\n",
        "  )[0]\n",
        "\n",
        "  gradients = gradients.view(gradients.size(0), -1)\n",
        "  gradient_penalty = torch.mean((gradients.norm(2, dim = 1) -1) ** 2)\n",
        "\n",
        "  return gradient_penalty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaAyfddkY_rt"
      },
      "source": [
        "The following functions define how a single training step works: one function for the critic and two for the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1pIJ2T8zDtW"
      },
      "outputs": [],
      "source": [
        "def w_gen_train_step(L, ab_real, ab_fake, fake_imgs, critic, g,  g_opt, device, C_L1 = 100) :\n",
        "\n",
        "  g.train()\n",
        "\n",
        "  g_opt.zero_grad()\n",
        "\n",
        "  fake_output = critic(fake_imgs)\n",
        "\n",
        "  G_WGAN_loss = -torch.mean(fake_output)\n",
        "  G_L1_loss =  L1_loss(ab_fake, ab_real) * C_L1\n",
        "  G_loss = G_WGAN_loss + G_L1_loss\n",
        "\n",
        "  G_loss.backward()\n",
        "  g_opt.step()\n",
        "\n",
        "  return {\"G_WGAN_loss\" : G_WGAN_loss.item(), \"G_L1_loss\" : G_L1_loss.item(), \"G_loss\" : G_loss.item()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgLElJxky9Si"
      },
      "source": [
        "Train step for the generator only with L1 norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHNjg4Jgy8ta"
      },
      "outputs": [],
      "source": [
        "def w_gen_train_step_L1(L, ab_real, ab_fake, fake_imgs, critic, g,  g_opt, device, adversial = False, C_L1 = 100 ) :\n",
        "\n",
        "  g.train()\n",
        "\n",
        "  g_opt.zero_grad()\n",
        "\n",
        "\n",
        "  G_loss = None\n",
        "\n",
        "  if adversial:\n",
        "\n",
        "    fake_output = critic(fake_imgs)\n",
        "    G_WGAN_loss = -torch.mean(fake_output)\n",
        "    G_L1_loss = 0\n",
        "    G_loss = G_WGAN_loss\n",
        "\n",
        "  else:\n",
        "    G_L1_loss =  L1_loss(ab_fake, ab_real) * C_L1\n",
        "    G_WGAN_loss = 0\n",
        "    G_loss = G_L1_loss\n",
        "\n",
        "  G_loss = G_WGAN_loss + G_L1_loss\n",
        "\n",
        "  G_loss.backward()\n",
        "  g_opt.step()\n",
        "\n",
        "\n",
        "  if adversial:\n",
        "\n",
        "    G_WGAN_loss = G_WGAN_loss.item()\n",
        "  else:\n",
        "\n",
        "    G_L1_loss = G_L1_loss.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return {\"G_WGAN_loss\" : G_WGAN_loss, \"G_L1_loss\" : G_L1_loss, \"G_loss\" : G_loss.item()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5dYyesHzbMH"
      },
      "source": [
        "Critic train step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1-j1aq4zdQ-"
      },
      "outputs": [],
      "source": [
        "def w_critic_train_step(L, ab_real, fake_imgs, critic, critic_opt, device, C_GP = 10) :\n",
        "\n",
        "  critic.train()\n",
        "\n",
        "  #forward\n",
        "  real_imgs = torch.cat([L, ab_real], dim = 1)\n",
        "\n",
        "  critic_opt.zero_grad()\n",
        "\n",
        "  real_output = critic(real_imgs)\n",
        "  fake_output = critic(fake_imgs.detach())\n",
        "\n",
        "  D_loss_real = torch.mean(real_output)\n",
        "  D_loss_fake = torch.mean(fake_output)\n",
        "  GP = GP_penalty_term(critic, real_imgs.data, fake_imgs.data, device) * C_GP\n",
        "\n",
        "  D_loss = - D_loss_real + D_loss_fake + GP\n",
        "\n",
        "  D_loss.backward()\n",
        "  critic_opt.step()\n",
        "\n",
        "  return {\"D_loss_real\" : -D_loss_real.item(), \"D_loss_fake\" : D_loss_fake.item(), \"D_loss\" : D_loss.item(), \"GP\" : GP.item()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRmxEXyF0AgJ"
      },
      "source": [
        "## 7.2 Train functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laMms9hR0F4Q"
      },
      "source": [
        "### 7.2.1. L1 loss only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XSKJ8A1UPjA"
      },
      "source": [
        "The following function allows to train the generator only (we pass the critic only for the saving)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6blCUEdU0JpL"
      },
      "outputs": [],
      "source": [
        "def wgan_train_L1(dataloader, epochs, g, device, g_opt, print_every, critic, c_opt, C_L1 = 100, last_epoch_done = None) :\n",
        "\n",
        "\n",
        "  #loss tracker da modificare\n",
        "\n",
        "  losstracker = WLossTracker()\n",
        "  \n",
        "\n",
        "  for epoch in range(epochs) : \n",
        "\n",
        "    g.train()\n",
        "\n",
        "    losstracker.set_to_zero()\n",
        "    losstracker.update_D_losses({\"D_loss_real\" : 0, \"D_loss_fake\" : 0, \"D_loss\" : 0, \"GP\" : 0}, 32)\n",
        "    progress_bar = tqdm(enumerate(dataloader), total = len(dataloader))\n",
        "\n",
        "    for i, batch in progress_bar :\n",
        "\n",
        "      L = batch[0].to(device)\n",
        "      ab = batch[1].to(device)\n",
        "\n",
        "      ab_fake = g(L)\n",
        "      fake_imgs = torch.cat([L, ab_fake], dim = 1)\n",
        "                                  \n",
        "      G_losses = w_gen_train_step_L1(L, ab, ab_fake, fake_imgs, None,  g,  g_opt, device)\n",
        "      losstracker.update_G_losses(G_losses, L.shape[0])\n",
        "\n",
        "      if (i + 1) % print_every == 0 :\n",
        "        #show_results(L[:3], ab[:3], ab_fake[:3])\n",
        "        losstracker.avg_losses()\n",
        "        losstracker.print_losses()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "    #SAVING MODELS + OPTs\n",
        "    print(\"Saving model checkpoint\")\n",
        "    add = 0 if last_epoch_done == None else 1+last_epoch_done\n",
        "\n",
        "    #compute avg losses over the epoch\n",
        "    losses = losstracker.avg_losses()\n",
        "\n",
        "    #save\n",
        "    if epoch == (epochs -1):\n",
        "      save_generator(g)\n",
        "    else:\n",
        "      wsave_checkpoint(epoch+add, g, critic, g_opt, c_opt, losses)\n",
        "\n",
        "\n",
        "    #save losses in csv\n",
        "\n",
        "    update_csv(epoch+add, losses, columns = wloss_names, path = \"/content/wlosses.csv\")\n",
        "\n",
        "    print(f'Epoch {epoch+add} finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWyq9Jgw0Pp1"
      },
      "source": [
        "### 7.2.2 L1 loss + WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlhgjG0F0Sr6"
      },
      "outputs": [],
      "source": [
        "def wgan_train(dataloader, epochs, g, critic, device, critic_opt, g_opt, print_every, Cs = {\"L1\" : 100, \"GP\" : 10},last_epoch_done = None, n_critic = 5) :\n",
        "\n",
        "  C_L1 = Cs[\"L1\"]\n",
        "  C_GP = Cs[\"GP\"]\n",
        "  #loss tracker da modificare\n",
        "\n",
        "  losstracker = WLossTracker()\n",
        "\n",
        "  for epoch in range(epochs) : \n",
        "\n",
        "    losstracker.set_to_zero()\n",
        "    progress_bar = tqdm(enumerate(dataloader), total = len(dataloader))\n",
        "\n",
        "    for i, batch in progress_bar :\n",
        "\n",
        "      L = batch[0].to(device)\n",
        "      ab = batch[1].to(device)\n",
        "\n",
        "      ab_fake = g(L)\n",
        "      fake_imgs = torch.cat([L, ab_fake], dim = 1)\n",
        "      \n",
        "     \n",
        "      D_losses = w_critic_train_step(L, ab, fake_imgs, critic, critic_opt, device, C_GP)\n",
        "\n",
        "      losstracker.update_D_losses(D_losses, L.shape[0])\n",
        "\n",
        "\n",
        "      if (i + 1) % n_critic == 0 :\n",
        "\n",
        "        \n",
        "        G_losses = w_gen_train_step(L, ab, ab_fake, fake_imgs, critic, g,  g_opt, device, C_L1 = C_L1 )\n",
        "        losstracker.update_G_losses(G_losses, L.shape[0])\n",
        "\n",
        "        if (i + 1) % print_every == 0 :\n",
        "            show_results(L[:3], ab[:3], ab_fake[:3])\n",
        "            losstracker.avg_losses()\n",
        "            losstracker.print_losses()\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "    #SAVING MODELS + OPTs\n",
        "    print(\"Saving model checkpoint\")\n",
        "    add = 0 if last_epoch_done == None else 1+last_epoch_done\n",
        "\n",
        "    #compute avg losses over the epoch\n",
        "    losses = losstracker.avg_losses()\n",
        "\n",
        "    #save\n",
        "    if epoch == (epochs -1):\n",
        "      save_generator(g)\n",
        "    else:\n",
        "      wsave_checkpoint(epoch+add, g, critic, g_opt, critic_opt, losses)\n",
        "\n",
        "\n",
        "    #save losses in csv\n",
        "\n",
        "    update_csv(epoch+add, losses, columns = wloss_names, path = \"/content/wlosses.csv\")\n",
        "\n",
        "    print(f'Epoch {epoch+add} finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rho4nI-kbrvz"
      },
      "source": [
        "## 7.3 Start L1 training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eImfCDrbuMd"
      },
      "outputs": [],
      "source": [
        "#training phase\n",
        "\n",
        "#create csv to save losses\n",
        "create_csv()\n",
        "\n",
        "EPOCHS = 60\n",
        "print_every = 150\n",
        "wgan_train_L1(train_dataloader, EPOCHS, G, device, G_opt, print_every, C, C_opt, C_L1 = 100, last_epoch_done = None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du5PuT4unDUT"
      },
      "source": [
        "## 7.4 Resume training L1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmGdYd082X75"
      },
      "source": [
        "In the case in which the training (with only the L1 loss) is interrupted, you can resume the training with this cell: firstly upload the last .pt saved during training ('WGAN_training.pt') on Colab (if you have changed either the name of the file or the path, '/content/', you just specify to 'load_checkpoint' as extra argument the path. Have a look to the definition of the function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXFY8ggj1fNR"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 60\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "C = PatchDiscriminator(normalization_type = \"instance\").to(device)\n",
        "\n",
        "lr_G = 2e-4 \n",
        "lr_C = 2e-4\n",
        "\n",
        "betas_G = (0.5, 0.999)\n",
        "betas_C = (0.0, 0.9) # RMSProp\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)   \n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)\n",
        "\n",
        "epoch, check_point_losses = wload_checkpoint(G, C, G_opt, C_opt)\n",
        "\n",
        "print(check_point_losses)\n",
        "\n",
        "\n",
        "epochs_left = EPOCHS - epoch  - 1   \n",
        "print_every = 150\n",
        "wgan_train_L1( train_dataloader, EPOCHS, G, device, G_opt,print_every, C, C_opt, last_epoch_done = epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbkZO8Qn1v1p"
      },
      "source": [
        "## 7.5 Start training L1 + WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC43gUKD1tBD"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 80\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "C = PatchDiscriminator(normalization_type = \"instance\").to(device)\n",
        "     \n",
        "lr_G = 2e-4 \n",
        "lr_C = 2e-4 \n",
        "\n",
        "betas_G = (0.5, 0.999)\n",
        "betas_C = (0.0, 0.9) # RMSProp\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)   \n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)\n",
        "\n",
        "epoch, check_point_losses = wload_checkpoint(G, C, G_opt, C_opt)\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)   \n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)\n",
        "\n",
        "print(check_point_losses)\n",
        "\n",
        "\n",
        "epochs_left = EPOCHS - epoch  - 1   \n",
        "print_every = 150    \n",
        "\n",
        "\n",
        "wgan_train( train_dataloader, epochs_left, G, C, device, C_opt, G_opt, print_every, Cs = {\"L1\": 1, \"GP\" : 1}, last_epoch_done = epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHtB_U3g2kTR"
      },
      "source": [
        "## 7.6 Resume training L1 + WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GiwZzChnGck"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 120\n",
        " \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "C = PatchDiscriminator(normalization_type = \"instance\").to(device)\n",
        "\n",
        "lr_G = 2e-4 \n",
        "lr_C = 2e-4\n",
        "\n",
        "betas_G = (0.5, 0.999)\n",
        "betas_C = (0.0, 0.9) # RMSProp\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)   \n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)\n",
        "\n",
        "epoch, check_point_losses = wload_checkpoint(G, C, G_opt, C_opt)\n",
        "\n",
        "\n",
        "print(check_point_losses)\n",
        "\n",
        "\n",
        "epochs_left = EPOCHS - epoch  - 1   \n",
        "print_every = 150     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "wgan_train( train_dataloader, epochs_left, G, C, device, C_opt, G_opt, print_every, Cs = {\"L1\": 1, \"GP\" : 1}, last_epoch_done = epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZdPplguOD1Y"
      },
      "source": [
        "## 8.4 Load and test Generator (to test properly the generator look at the other notebooks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfx8L7AkwqQZ",
        "outputId": "c2e799cd-9dd9-4a76-fe3c-e77504be3cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint at epoch 59 loaded\n",
            "{'G_WGAN_loss': 0.0, 'D_loss': 0.0, 'G_loss': 5.827366714477539}\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 120\n",
        " \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "C = PatchDiscriminator(normalization_type = \"instance\").to(device)\n",
        "\n",
        "lr_G = 2e-4 \n",
        "lr_C = 2e-4\n",
        "\n",
        "betas_G = (0.5, 0.999)\n",
        "betas_C = (0.0, 0.9) # RMSProp\n",
        "\n",
        "G_opt = optim.Adam(G.parameters(), lr=lr_G, betas=betas_G)   \n",
        "C_opt = optim.Adam(C.parameters(), lr=lr_C, betas=betas_C)\n",
        "\n",
        "epoch, check_point_losses = wload_checkpoint(G, C, G_opt, C_opt,\"/content/WGAN_training_59.pt\")\n",
        "\n",
        "\n",
        "print(check_point_losses)\n",
        "\n",
        "save_generator(G, \"WGAN_9k_60.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdosKfULOKOO"
      },
      "source": [
        "The following cells load the generator and show the results with some new images. First of all load a file with the paths for images of the animals dataset (not used during training) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc9ffSU3On5S"
      },
      "outputs": [],
      "source": [
        "files.upload(); #val_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2azYxO4PDVW",
        "outputId": "95821280-755c-4d8e-90a8-aee414b9fbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# images of animals for testing: 2400\n"
          ]
        }
      ],
      "source": [
        "filename = \"val_animals.txt\"\n",
        "\n",
        "def read_lines(path):\n",
        "\n",
        "  lines = None\n",
        "\n",
        "  with open(path) as file:\n",
        "    lines = [line.rstrip() for line in file]\n",
        "\n",
        "  return lines\n",
        "\n",
        "animals_paths = read_lines(filename)\n",
        "\n",
        "print(f\"# images of animals for testing: {len(animals_paths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xyTfsWlPibR"
      },
      "source": [
        "Add the other images of COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxBUFkDqPoPM",
        "outputId": "281b660d-a935-4500-cb96-5faa131a2a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# images for testing: 17637\n"
          ]
        }
      ],
      "source": [
        "test_paths = animals_paths\n",
        "\n",
        "for path in paths:\n",
        "  \n",
        "  if path not in training_paths:\n",
        "\n",
        "    test_paths.append(path)\n",
        "\n",
        "print(f\"# images for testing: {len(test_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4p7PCK6QVqP"
      },
      "outputs": [],
      "source": [
        "np.random.seed)\n",
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "test_paths = np.array(test_paths)\n",
        "np.random.shuffle(test_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcNOcFD_RQkV"
      },
      "source": [
        "Create dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjFh79oiRMxE"
      },
      "outputs": [],
      "source": [
        "SIZE = 256\n",
        "batch_size = 3\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  transforms.InterpolationMode.BILINEAR),\n",
        "            ])\n",
        "\n",
        "test_dataset = GrayToColorDataset(test_paths, test_transform)\n",
        "\n",
        "PIN_MEMORY = True\n",
        "N_WORKERS = 2\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=N_WORKERS,\n",
        "                            pin_memory=PIN_MEMORY, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAeeiClnRflJ"
      },
      "source": [
        "load generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNQe40vVRiyE"
      },
      "outputs": [],
      "source": [
        "#G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device);\n",
        "\n",
        "#load_generator(G);\n",
        "\n",
        "G = GeneratorUNet(1,2,8,64, \"batchnorm\").to(device)\n",
        "load_generator(G,\"/content/WGAN_9k_60.pt\")\n",
        "\n",
        "#G.train(); #\n",
        "G.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaS7TwbkRzlS"
      },
      "source": [
        "Show results cicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GXuWb4nZRzBj"
      },
      "outputs": [],
      "source": [
        "def test_generator(G, device, dataloader, n_batcher_to_show = 4):\n",
        "\n",
        "  for i,batch in enumerate(dataloader):\n",
        "        print(f\"Results for batch {i+1}\")\n",
        "        L = batch[0].to(device)\n",
        "        ab = batch[1].to(device)\n",
        "\n",
        "        ab_fake = G(L)\n",
        "\n",
        "        show_results(L, ab, ab_fake)\n",
        "\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "        if i == n_batcher_to_show -1:\n",
        "          break\n",
        "\n",
        "test_generator(G, device, test_dataloader, 10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}